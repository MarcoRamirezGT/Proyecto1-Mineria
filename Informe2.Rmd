---
title: "Proyecto: Presentacion de resultados"
author: "Marco Ramirez 19588, Alfredo Quezada, Estuardo Hernandez, Eduardo Ramirez"
date: "13/5/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library("e1071")
library(caret)
library('MLmetrics')
library(rpart)
library(tree)
library(rpart.plot)
library(randomForest)

# Read the data into a table from the file

#Prediccion de la variable Clase de union
db <- readRDS("db10_20.rds")

df<-db[,c("Departamento de registro","Municipio de registro","Escolaridad del hombre","Escolaridad de la mujer","Grupo etnico del hombre","Grupo etnico de la mujer", "Clase de union")]

ws<-db[,c("Clase de union")]
ws<- haven::as_factor(ws)

m1<-rpart(ws~ ., data = df, method = "anova")

```

## Árbol de Regresión

La variable de respuesta utilizada para este método fue la clase de unión de cada matrimonio registrado. Debido a que el objetivo es obtener una buena prediccion de la variable "clase de unión" utilizando las demás variables como "Departamento de registro", "Municipio de registro", "Escolaridad del hombre", "Escolaridad de la mujer", "Grupo étnico del hombre" y "Grupo étnico de la mujer". Y este mismo conjunto de variables fue el mejor a la hora de predecir la variable respuesta.


Los datos se encuentran balanceados porque todos son numéricos de longitudes similares.
En este caso, se tuvo que transformar la columna "Clase de unión" a factor para poder graficar el árbol, ya que era de tipo numérico con etiquetas.

```{r}
rpart.plot(m1, type = 3, digits = 3, fallen.leaves = TRUE )
```

Este árbol de regresión se creó en base a variables numéricas con la finalidad de precedir la clase de unión del matrimonio. Mediante este arbol se clasifica en qué clase de unión está el matrimonio, si la clase es menor que 3 y menor que 2, determinamos que el 5.7% de los matrimonios están bajo la clase 1 de "Comunidad absoluta".

Si la clase es menor que 3, pero mayor o igual a dos, determinamos que el 2% de los matrimonios están bajo la clase 2 de "Separación absoluta". Si la clase es mayor o igual a 3 y menor que 6, determinamos que el 87.9% de los matrimonios están bajo la clase 3 de "Comunidad de gananciales". Y por último, si la clase es mayor o igual que 3, pero mayor o igual que 6, determinamos que el 4.5% de los matrimonios están bajo la clase 9 de "No especificado".

Se puede decir que el árbol de regresión fue exitoso, ya que el algoritmo logró hacer clasificaciones a partir de varibales que nosotros consideramos como claves, así mismo fue capaz de separarlas en categorías, también se puede ver que por las mismas clasificaciones de las variables, la prediccion es bastante lógica, porque la clase de unión 3 de "Comunidad de gananciales" es la que más se usa y es la que tiene el porcentaje más alto.

```{r}
#Bayes 
#Usamos el 70% de datos
porcentaje<-0.7
#El experimento debe ser repetible
set.seed(1234)

corte <- sample(nrow(db),nrow(db)*porcentaje)
#Entrenamiento
train<-db[corte,]

#Prueba
test<-db[-corte,]
```

## Naive Bayes

En cada uno de los modelos realizados se utilizo laplace, ya que el suavizado con el parametro de laplace nos dice que mientras mayor sea el valor, esto hara que los modelos sean iguales por lo que nos sirve para poder unificar y crear 3 modelos con la misma variable respuesta pero cada una con diferente parametro laplace y 2 modelos con otro tipo de variable respuesta para poder ir realizando distintas pruebas, esto con la finalidad de predecir la clase de union del matrimonio.

Si recordamos, el tema principal de esta investigacion era determinar y encontrar una tendencia entre los matrimonios registrados en Guatemala y las variables respuesta principales que utilizamos en estos modelos fueron "Clase de Union" y "Escolaridad de hombre y mujer" ya que al relacionar estas dos variables podemos obtener una prediccion bastante buena para determinar si existe una relacion entre las clases de union de los matrimonios.


## Modelo 1 : Variable respuesta es clase de union

```{r}

# use NB classifier
NB = naiveBayes(train$`Clase de union` ~.,train,laplace = 0.01)

# Predict with Test Data
predicted_value1 = predict(NB,test)
expected_value = factor(test$`Clase de union`)

#Creating confusion matrix
confuisonMatrix <- confusionMatrix(data=predicted_value1, reference = expected_value)

#Display results 
confuisonMatrix
Accuracy(predicted_value1,expected_value)
table(expected_value,predicted_value1)

```


```{r}

NB = naiveBayes(train$`Clase de union` ~.,train)

# Predict with Test Data
predicted_value2 = predict(NB,test)
expected_value = factor(test$`Clase de union`)

#Creating confusion matrix
confuisonMatrix <- confusionMatrix(data=predicted_value2, reference = expected_value)

#Display results 
confuisonMatrix
Accuracy(predicted_value2,expected_value)
table(expected_value,predicted_value2)

```

## Modelo 3 : Variable respuesta es clase de union

```{r}

# use NB classifier
NB = naiveBayes(train$`Clase de union` ~.,train,laplace = 3)

# Predict with Test Data
predicted_value3 = predict(NB,test)
expected_value = factor(test$`Clase de union`)

#Creating confusion matrix
confuisonMatrix <- confusionMatrix(data=predicted_value3, reference = expected_value)

#Display results 
confuisonMatrix
Accuracy(predicted_value3,expected_value)
table(expected_value,predicted_value3)


```

## Modelo 4 : Variable respuesta Escolaridad del hombre y mujer

```{r}

#Escolaridad del hombre
NB = naiveBayes(train$`Escolaridad del hombre` ~.,train,laplace = 0.01)

# Predict with Test Data
predicted_value4 = predict(NB,test)
expected_value = factor(test$`Escolaridad del hombre`)

#Creating confusion matrix
confuisonMatrix <- confusionMatrix(data=predicted_value4, reference = expected_value)

#Display results 
confuisonMatrix
Accuracy(predicted_value4,expected_value)
table(expected_value,predicted_value4)
```

## Modelo 5 : Variable respuesta Escolaridad del hombre y mujer
```{r}
#Escolaridad de la mujer
NB = naiveBayes(train$`Escolaridad de la mujer` ~.,train,laplace = 3)

# Predict with Test Data
predicted_value5 = predict(NB,test)
expected_value = factor(test$`Escolaridad de la mujer`)

#Creating confusion matrix
confuisonMatrix <- confusionMatrix(data=predicted_value5, reference = expected_value)

#Display results 
confuisonMatrix
Accuracy(predicted_value5,expected_value)
table(expected_value,predicted_value5)

```
RMSE de los modelos para evaluar si tienen overfitting
```{r message=FALSE, warning=FALSE}
library(ModelMetrics)
#Modelo 1
rmse(test$`Clase de union`,predicted_value1)
#Modelo 2
rmse(test$`Clase de union`,predicted_value2)
#Modelo 3
rmse(test$`Clase de union`,predicted_value3)
#Modelo 4
rmse(test$`Clase de union`,predicted_value4)
#Modelo 5
rmse(test$`Clase de union`,predicted_value5)
```
De los diferentes modelos que realizamos el que realizo la mejor prediccion fue el primer modelo ya que nos dio un 80% de precision, y esto fue porque existen muchos valores de prediccion que se calcularon con laplace en relacion al valor esperado y estos eran iguales. Entre mas valores iguales existan, la prediccion sera mejor.

En las tablas donde se aplicaron las matrices de confusion tambien podemos observar que la precisión del 80% y podemos observar como ciertos valores no eran los mismos pero fue la que mas valores iguales obstuvo de los 4 modelos.
